---
abstract: Conditional GANs have matured in recent years and are able to generate
  high-quality realistic images. However, the computational resources and the
  training data required for the training of high-quality GANs are enormous, and
  the study of transfer learning of these models is therefore an urgent topic.
  In this paper, we explore the transfer from high-quality pre-trained
  unconditional GANs to conditional GANs. To this end, we propose
  hypernetwork-based adaptive weight modulation. In addition, we introduce a
  self-initialization procedure that does not require any real data to
  initialize the hypernetwork parameters. To further improve the sample
  efficiency of the knowledge transfer, we propose to use a self-supervised
  (contrastive) loss to improve the GAN discriminator. In extensive experiments,
  we validate the efficiency of the hypernetworks, self-initialization and
  contrastive loss for knowledge transfer on several standard benchmarks.
slides: null
url_pdf: https://arxiv.org/pdf/2112.02219.pdf
publication_types:
  - "1"
authors:
  - HÃ©ctor Laria
  - Yaxing Wang
  - Joost van de Weijer
  - Bogdan Raducanu
summary: We explore first the setting from unconditional GANs to conditional GANs.
url_dataset: "#"
url_project: ""
publication_short: In *arxiv*
url_source: "#"
url_video: "#"
publication: In *Arxiv libary*
featured: true
date: 2022-03-20T05:00:35.069Z
url_slides: ""
title: "Hyper-GAN: Transferring Unconditional to Conditional GANs with HyperNetworks"
tags:
  - Source Themes
links:
  - name: Custom Link
    url: http://example.org
projects:
  - internal-project
image:
  caption: ""
  focal_point: ""
  preview_only: false
  filename: featured.png
publishDate: 2017-01-01T00:00:00Z
url_poster: "#"
url_code: "#"
doi: ""
---

{{% callout note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
